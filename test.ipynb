{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(r\"./data/monash/monash-df.pkl\", \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ad9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def yield_data(pickle_file_path=\"./data/monash/monash-df.pkl\"):\n",
    "    \"\"\"\n",
    "    Generator function to yield objects one at a time from a pickle file.\n",
    "\n",
    "    Args:\n",
    "        pickle_file_path (str): Path to the pickle file.\n",
    "\n",
    "    Yields:\n",
    "        dict: A dictionary with file name, df, freq as keys.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the pickle file doesn't exist.\n",
    "        pickle.UnpicklingError: If the pickle file is corrupted.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(pickle_file_path, \"rb\") as f:\n",
    "            while True:\n",
    "                try:\n",
    "                    obj = pickle.load(f)\n",
    "                    items = [i for i in obj.items()][0]\n",
    "                    yield {\n",
    "                        \"name\": items[0].split('.')[0],\n",
    "                        \"df\": items[1][0],\n",
    "                        \"freq\": items[1][1],\n",
    "                    }\n",
    "                except EOFError:\n",
    "                    break\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Pickle file not found: {pickle_file_path}\")\n",
    "    except pickle.UnpicklingError:\n",
    "        raise pickle.UnpicklingError(\"Corrupted pickle file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f385352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = yield_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8045a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_time_series(df, frequency):\n",
    "    \"\"\"\n",
    "    Convert DataFrame with series_value lists to a time series DataFrame, handling varied frequencies.\n",
    "    If series_value contains NaN, that series will be skipped.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with series_name, start_timestamp, series_value.\n",
    "        frequency (str): Frequency of the series (e.g., '4_seconds', 'half_hourly', 'daily').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with timestamps as index and series_name as columns.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the frequency is unsupported.\n",
    "    \"\"\"\n",
    "    freq_map = {\n",
    "        '4_seconds': '4s',\n",
    "        'minutely': 'min',\n",
    "        'hourly': 'h',\n",
    "        'half_hourly': '30min',\n",
    "        'daily': 'D',\n",
    "        'weekly': 'W',\n",
    "        'monthly': 'ME',\n",
    "        'quarterly': 'Q',\n",
    "        'yearly': 'Y'\n",
    "    }\n",
    "\n",
    "    pandas_freq = freq_map.get(frequency)\n",
    "    if pandas_freq is None:\n",
    "        raise ValueError(f\"Unsupported frequency: {frequency}\")\n",
    "    \n",
    "    series_dict = {}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        series_name = row['series_name']\n",
    "        \n",
    "        try:\n",
    "            start_time = pd.to_datetime(row['start_timestamp'])\n",
    "        except KeyError:\n",
    "            start_time = pd.Timestamp(\"2000-01-01 00:00:00\")\n",
    "\n",
    "        values = row['series_value']\n",
    "        if any(pd.isna(v) for v in values):\n",
    "            continue\n",
    "        timestamps = pd.date_range(\n",
    "            start=start_time, periods=len(values), freq=pandas_freq)\n",
    "        \n",
    "        series_dict[series_name] = pd.Series(values, index=timestamps)\n",
    "\n",
    "    ts_df = pd.DataFrame(series_dict)\n",
    "    return ts_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc3ec871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0 ('kdd_cup_2018_dataset_without_missing_values') columns: ['series_name', 'city', 'station', 'air_quality_measurement', 'start_timestamp', 'series_value']\n",
      "DataFrame 1 ('solar_4_seconds_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 2 ('pedestrian_counts_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 3 ('traffic_hourly_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 4 ('temperature_rain_dataset_without_missing_values') columns: ['series_name', 'station_id', 'obs_or_fcst', 'start_timestamp', 'series_value']\n",
      "DataFrame 5 ('saugeenday_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 6 ('tourism_monthly_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 7 ('bitcoin_dataset_without_missing_values') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 8 ('wind_farms_minutely_dataset_without_missing_values') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 9 ('cif_2016_dataset') columns: ['series_name', 'horizon', 'series_value']\n",
      "DataFrame 10 ('solar_weekly_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 11 ('kaggle_web_traffic_dataset_without_missing_values') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 12 ('m1_yearly_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 13 ('tourism_yearly_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 14 ('fred_md_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 15 ('traffic_weekly_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 16 ('m3_monthly_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 17 ('covid_deaths_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 18 ('us_births_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 19 ('weather_dataset') columns: ['series_name', 'series_type', 'series_value']\n",
      "DataFrame 20 ('m4_monthly_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 21 ('m1_quarterly_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 22 ('kaggle_web_traffic_weekly_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 23 ('dominick_dataset') columns: ['series_name', 'series_value']\n",
      "DataFrame 24 ('car_parts_dataset_without_missing_values') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 25 ('m4_weekly_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 26 ('rideshare_dataset_without_missing_values') columns: ['series_name', 'source_location', 'provider_name', 'provider_service', 'type', 'start_timestamp', 'series_value']\n",
      "DataFrame 27 ('m3_yearly_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 28 ('m1_monthly_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 29 ('m4_quarterly_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 30 ('wind_4_seconds_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 31 ('m4_yearly_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 32 ('electricity_hourly_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 33 ('australian_electricity_demand_dataset') columns: ['series_name', 'state', 'start_timestamp', 'series_value']\n",
      "DataFrame 34 ('m3_quarterly_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 35 ('vehicle_trips_dataset_without_missing_values') columns: ['series_name', 'base_number', 'base_name', 'type', 'start_timestamp', 'series_value']\n",
      "DataFrame 36 ('london_smart_meters_dataset_without_missing_values') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 37 ('nn5_daily_dataset_without_missing_values') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 38 ('hospital_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 39 ('m4_daily_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 40 ('m4_hourly_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 41 ('sunspot_dataset_without_missing_values') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "DataFrame 42 ('tourism_quarterly_dataset') columns: ['series_name', 'start_timestamp', 'series_value']\n",
      "\n",
      "Indices of DataFrames missing 'start_timestamp': [9, 19, 23]\n"
     ]
    }
   ],
   "source": [
    "data_generator = yield_data()\n",
    "\n",
    "missing_indices = []\n",
    "\n",
    "for idx, item in enumerate(data_generator):\n",
    "    df = item['df']\n",
    "    name = item['name']\n",
    "\n",
    "    # Print the column names\n",
    "    print(f\"DataFrame {idx} ('{name}') columns:\", df.columns.tolist())\n",
    "\n",
    "    # Check for missing 'start_timestamp'\n",
    "    if 'start_timestamp' not in df.columns:\n",
    "        missing_indices.append(idx)\n",
    "\n",
    "print(\"\\nIndices of DataFrames missing 'start_timestamp':\", missing_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b68cf888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'dominick_dataset',\n",
       " 'df':        series_name                                       series_value\n",
       " 0               T1  [41.83, 0.0, 0.0, 0.0, 41.83, 0.0, 0.0, 0.0, 0...\n",
       " 1               T2  [68.85, 68.85, 0.0, 68.85, 0.0, 68.85, 0.0, 0....\n",
       " 2               T3  [0.0, 0.0, 0.0, 62.62, 62.62, 62.62, 0.0, 62.6...\n",
       " 3               T4  [67.99, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
       " 4               T5  [0.0, 0.0, 0.0, 62.58, 62.58, 0.0, 0.0, 62.58,...\n",
       " ...            ...                                                ...\n",
       " 115699     T115700  [0.0, 27.47, 33.54, 33.54, 33.56, 33.67, 33.67...\n",
       " 115700     T115701  [0.0, 26.31, 31.49, 33.67, 33.67, 33.67, 33.67...\n",
       " 115701     T115702  [0.0, 26.54, 33.26, 33.26, 33.26, 33.67, 33.67...\n",
       " 115702     T115703  [0.0, 27.39, 31.48, 33.21, 33.38, 33.67, 33.67...\n",
       " 115703     T115704  [0.0, 26.89, 0.0, 33.67, 33.67, 33.67, 33.67, ...\n",
       " \n",
       " [115704 rows x 2 columns],\n",
       " 'freq': 'weekly'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "data_generator = yield_data()\n",
    "i = 23\n",
    "next(islice(data_generator, i, i + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1979294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "data_generator = yield_data()\n",
    "\n",
    "for data in data_generator:\n",
    "    prepare_time_series(data['df'], data['freq'])\n",
    "    print(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4cb5376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>...</th>\n",
       "      <th>T261</th>\n",
       "      <th>T262</th>\n",
       "      <th>T263</th>\n",
       "      <th>T264</th>\n",
       "      <th>T265</th>\n",
       "      <th>T266</th>\n",
       "      <th>T267</th>\n",
       "      <th>T268</th>\n",
       "      <th>T269</th>\n",
       "      <th>T270</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>16.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>31.7</td>\n",
       "      <td>23.2</td>\n",
       "      <td>21.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>10.7</td>\n",
       "      <td>9.4</td>\n",
       "      <td>17.5</td>\n",
       "      <td>29.9</td>\n",
       "      <td>23.1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>24.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>7.8</td>\n",
       "      <td>16.6</td>\n",
       "      <td>21.8</td>\n",
       "      <td>13.9</td>\n",
       "      <td>22.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 03:00:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15.8</td>\n",
       "      <td>18.6</td>\n",
       "      <td>18.6</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.1</td>\n",
       "      <td>12.8</td>\n",
       "      <td>23.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 04:00:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>22.4</td>\n",
       "      <td>16.3</td>\n",
       "      <td>20.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>5.4</td>\n",
       "      <td>20.4</td>\n",
       "      <td>23.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>22.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-31 19:00:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>44.8</td>\n",
       "      <td>18.7</td>\n",
       "      <td>16.9</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-31 20:00:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>44.8</td>\n",
       "      <td>18.7</td>\n",
       "      <td>16.9</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-31 21:00:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>44.8</td>\n",
       "      <td>18.7</td>\n",
       "      <td>16.9</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-31 22:00:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>44.8</td>\n",
       "      <td>18.7</td>\n",
       "      <td>16.9</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-31 23:00:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>44.8</td>\n",
       "      <td>18.7</td>\n",
       "      <td>16.9</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21818 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     T1  T2  T3  T4  T5  T6  T7  T8  T9  T10  ...  T261  T262  \\\n",
       "2017-01-01 00:00:01 NaN NaN NaN NaN NaN NaN NaN NaN NaN  NaN  ...  55.0  22.0   \n",
       "2017-01-01 01:00:01 NaN NaN NaN NaN NaN NaN NaN NaN NaN  NaN  ...  26.0  27.0   \n",
       "2017-01-01 02:00:01 NaN NaN NaN NaN NaN NaN NaN NaN NaN  NaN  ...  24.4  22.0   \n",
       "2017-01-01 03:00:01 NaN NaN NaN NaN NaN NaN NaN NaN NaN  NaN  ...  15.8  18.6   \n",
       "2017-01-01 04:00:01 NaN NaN NaN NaN NaN NaN NaN NaN NaN  NaN  ...  22.4  16.3   \n",
       "...                  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...   ...   ...   \n",
       "2018-03-31 19:00:01 NaN NaN NaN NaN NaN NaN NaN NaN NaN  NaN  ...   9.8  23.6   \n",
       "2018-03-31 20:00:01 NaN NaN NaN NaN NaN NaN NaN NaN NaN  NaN  ...   9.8  23.6   \n",
       "2018-03-31 21:00:01 NaN NaN NaN NaN NaN NaN NaN NaN NaN  NaN  ...   9.8  23.6   \n",
       "2018-03-31 22:00:01 NaN NaN NaN NaN NaN NaN NaN NaN NaN  NaN  ...   9.8  23.6   \n",
       "2018-03-31 23:00:01 NaN NaN NaN NaN NaN NaN NaN NaN NaN  NaN  ...   9.8  23.6   \n",
       "\n",
       "                     T263  T264  T265  T266  T267  T268  T269  T270  \n",
       "2017-01-01 00:00:01  23.3  16.1   7.0  23.3  31.7  23.2  21.3   NaN  \n",
       "2017-01-01 01:00:01  17.5  10.7   9.4  17.5  29.9  23.1  25.9   NaN  \n",
       "2017-01-01 02:00:01  16.6   8.9   7.8  16.6  21.8  13.9  22.6   NaN  \n",
       "2017-01-01 03:00:01  18.6   8.5   5.4  18.6  19.1  12.8  23.4   NaN  \n",
       "2017-01-01 04:00:01  20.4   8.3   5.4  20.4  23.7  13.8  22.6   NaN  \n",
       "...                   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "2018-03-31 19:00:01  10.2   5.9   1.4   4.5  44.8  18.7  16.9   6.0  \n",
       "2018-03-31 20:00:01  10.2   5.9   1.4   4.5  44.8  18.7  16.9   6.0  \n",
       "2018-03-31 21:00:01  10.2   5.9   1.4   4.5  44.8  18.7  16.9   6.0  \n",
       "2018-03-31 22:00:01  10.2   5.9   1.4   4.5  44.8  18.7  16.9   6.0  \n",
       "2018-03-31 23:00:01  10.2   5.9   1.4   4.5  44.8  18.7  16.9   6.0  \n",
       "\n",
       "[21818 rows x 270 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_generator = yield_data()\n",
    "data = next(data_generator)\n",
    "prepare_time_series(data['df'], data['freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da23668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
